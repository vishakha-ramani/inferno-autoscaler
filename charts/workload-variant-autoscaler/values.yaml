wva:
  enabled: true

  image:
    repository: ghcr.io/llm-d-incubation/workload-variant-autoscaler
    tag: v0.4.1
  imagePullPolicy: Always

  metrics:
    enabled: true
    port: 8443
    secure: true
  
  reconcileInterval: 60s
    
  prometheus:
    monitoringNamespace: openshift-user-workload-monitoring
    serviceAccountName: "kube-prometheus-stack-prometheus"
    baseURL: "https://thanos-querier.openshift-monitoring.svc.cluster.local:9091"
    # Development security configuration (relaxed for easier development)
    tls:
      insecureSkipVerify: true   # Development: true, Production: false
      caCertPath: "/etc/ssl/certs/prometheus-ca.crt"
    # caCert: |  # Uncomment and provide your CA certificate
    #   -----BEGIN CERTIFICATE-----
    #   YOUR_CA_CERTIFICATE_HERE
    #   -----END CERTIFICATE-----

  experimental:
    enableModelTuner: false  # Enable experimental model tuner feature
    autoGuessInitialState: false  # When true: prefer metrics-based guessing over spec parameters

  # Environment variable to enable experimental hybrid-based optimization
  #  When "on", runs both capacity analyzer and model-based optimizer with arbitration
  #  When "model-only" runs model-based optimizer only
  #  When "off" or unset, runs capacity analyzer only (default, reactive mode)
  experimentalHybridOptimization: off  # Enable experimental hybrid optimization (default: off)
  scaleToZero: false  # Enable scaling variants to zero replicas (default: false)

  # Saturation-based scaling configuration
  # These thresholds determine when replicas are saturated and when to scale up
  capacityScaling:
    # Global defaults applied to all variants unless overridden
    default:
      kvCacheThreshold: 0.80      # Replica saturated if KV cache utilization >= threshold (0.0-1.0)
      queueLengthThreshold: 5     # Replica saturated if queue length >= threshold
      kvSpareTrigger: 0.1         # Scale-up if avg spare KV capacity < trigger (0.0-1.0)
      queueSpareTrigger: 3        # Scale-up if avg spare queue capacity < trigger
    
    # Per-model/namespace overrides (optional)
    # Example:
    # overrides:
    #   llm-d:
    #     modelID: "Qwen/Qwen3-0.6B"
    #     namespace: "llm-d-autoscaler"
    #     kvCacheThreshold: 0.70
    #     kvSpareTrigger: 0.35
    overrides: {}

llmd:
  namespace: llm-d-autoscaler
  modelName: ms-workload-autoscaler-llm-d-modelservice
  modelID: "Qwen/Qwen3-0.6B"

va:
  enabled: true
  tuned: true
  accelerator: H100
  sloTpot: 10
  sloTtft: 1000

hpa:
  enabled: true
  maxReplicas: 10
  targetAverageValue: "1"

vllmService:
  enabled: true
  nodePort: 30000
  interval: 15s
  scheme: http  # vLLM emulator runs on HTTP
