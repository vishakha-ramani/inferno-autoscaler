apiVersion: llmd.ai/v1alpha1
# Optimizing a variant, create only when the model is deployed and serving traffic
# this is for the collector the collect existing (previous) running metrics of the variant.
kind: VariantAutoscaling
metadata:
  # Unique name of the variant
  name: vllme-deployment 
  namespace: llm-d-sim
  labels:
    inference.optimization/acceleratorName: A100
# This is essentially static input to the optimizer
spec:
  # OpenAI API compatible name of the model
  modelID: default/default

  # Optional: Specify cost per replica for capacity-based cost optimization
  # Used by capacity analyzer when multiple variants can handle the load
  # Default: 10.0, Validation: Must be >= 0
  # variantCost: 10.0
  
  # Static profiled benchmarked data for a variant running on different accelerators
  modelProfile:
    accelerators:
      - acc: "A100"
        accCount: 1
        perfParms: 
          decodeParms:
            # Decode parameters for ITL equation: itl = alpha + beta * maxBatchSize
            alpha: "20.58"
            beta: "0.41"
          # Prefill parameters for TTFT equation: ttft = gamma + delta * tokens * maxBatchSize  
          prefillParms:
            gamma: "5.2"
            delta: "0.1"
        maxBatchSize: 4
