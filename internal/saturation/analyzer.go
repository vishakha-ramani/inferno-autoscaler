package saturation

import (
	"context"
	"fmt"
	"time"

	"github.com/llm-d-incubation/workload-variant-autoscaler/internal/interfaces"
	"github.com/llm-d-incubation/workload-variant-autoscaler/internal/logger"
)

// Analyzer implements the SaturationAnalyzer interface
type Analyzer struct{}

// NewAnalyzer creates a new saturation analyzer instance
func NewAnalyzer() interfaces.SaturationAnalyzer {
	return &Analyzer{}
}

// AnalyzeModelSaturation analyzes Saturation for all variants of a model.
// It aggregates metrics across all replicas (from all variants) and determines:
// 1. Which replicas are non-saturated
// 2. Average spare Saturation across non-saturated replicas
// 3. Whether to scale up (spare Saturation < trigger)
// 4. Whether scale-down is safe (worst-case simulation)
func (a *Analyzer) AnalyzeModelSaturation(
	ctx context.Context,
	modelID string,
	namespace string,
	replicaMetrics []interfaces.ReplicaMetrics,
	config interfaces.SaturationScalingConfig,
) (*interfaces.ModelSaturationAnalysis, error) {

	if len(replicaMetrics) == 0 {
		return &interfaces.ModelSaturationAnalysis{
			ModelID:         modelID,
			Namespace:       namespace,
			AnalyzedAt:      time.Now(),
			TotalReplicas:   0,
			ShouldScaleUp:   false,
			ShouldScaleDown: false,
			ScaleDownSafe:   false,
			VariantAnalyses: []interfaces.VariantSaturationAnalysis{},
		}, nil
	}

	analysis := &interfaces.ModelSaturationAnalysis{
		ModelID:    modelID,
		Namespace:  namespace,
		AnalyzedAt: time.Now(),
	}

	// Step 1: Group metrics by variant and calculate per-variant analysis
	// Pre-count variants to pre-allocate slices (avoids repeated slice reallocation)
	variantCounts := make(map[string]int)
	for _, metric := range replicaMetrics {
		variantCounts[metric.VariantName]++
	}

	// Pre-allocate slices with exact Saturation
	variantMap := make(map[string][]interfaces.ReplicaMetrics, len(variantCounts))
	for variant, count := range variantCounts {
		variantMap[variant] = make([]interfaces.ReplicaMetrics, 0, count)
	}

	// Populate with metrics (no reallocation needed)
	for _, metric := range replicaMetrics {
		variantMap[metric.VariantName] = append(variantMap[metric.VariantName], metric)
	}

	// Aggregate statistics across all replicas
	var totalSpareKv float64
	var totalSpareQueue float64
	var nonSaturatedCount int
	var maxKvUsage float64
	var maxQueueLen int

	variantAnalyses := make([]interfaces.VariantSaturationAnalysis, 0, len(variantMap))

	for variantName, metrics := range variantMap {
		variantAnalysis := a.analyzeVariant(variantName, metrics, config)
		variantAnalyses = append(variantAnalyses, variantAnalysis)

		// Aggregate across variants
		nonSaturatedCount += variantAnalysis.NonSaturatedCount
		totalSpareKv += variantAnalysis.AvgSpareKvCapacity * float64(variantAnalysis.NonSaturatedCount)
		totalSpareQueue += variantAnalysis.AvgSpareQueueLength * float64(variantAnalysis.NonSaturatedCount)

		// Track worst-case metrics
		if variantAnalysis.MaxKvCacheUsage > maxKvUsage {
			maxKvUsage = variantAnalysis.MaxKvCacheUsage
		}
		if variantAnalysis.MaxQueueLength > maxQueueLen {
			maxQueueLen = variantAnalysis.MaxQueueLength
		}
	}

	analysis.TotalReplicas = len(replicaMetrics)
	analysis.NonSaturatedCount = nonSaturatedCount
	analysis.VariantAnalyses = variantAnalyses

	// Step 2: Calculate average spare Saturation across all non-saturated replicas
	if nonSaturatedCount > 0 {
		analysis.AvgSpareKvCapacity = totalSpareKv / float64(nonSaturatedCount)
		analysis.AvgSpareQueueLength = totalSpareQueue / float64(nonSaturatedCount)
	}

	// Step 3: Determine scale-up recommendation
	analysis.ShouldScaleUp, analysis.ScaleUpReason = a.shouldScaleUp(
		analysis.AvgSpareKvCapacity,
		analysis.AvgSpareQueueLength,
		config,
	)

	// Step 4: Determine if scale-down is safe
	analysis.ShouldScaleDown, analysis.ScaleDownSafe = a.isScaleDownSafe(
		replicaMetrics,
		config,
	)

	logger.Log.Debugf("saturation analysis completed: modelID=%s, namespace=%s, totalReplicas=%d, nonSaturated=%d, avgSpareKv=%.3f, avgSpareQueue=%.1f, shouldScaleUp=%v, scaleDownSafe=%v",
		modelID, namespace, analysis.TotalReplicas, nonSaturatedCount,
		analysis.AvgSpareKvCapacity, analysis.AvgSpareQueueLength,
		analysis.ShouldScaleUp, analysis.ScaleDownSafe)

	return analysis, nil
}

// analyzeVariant analyzes Saturation for a single variant
func (a *Analyzer) analyzeVariant(
	variantName string,
	metrics []interfaces.ReplicaMetrics,
	config interfaces.SaturationScalingConfig,
) interfaces.VariantSaturationAnalysis {

	analysis := interfaces.VariantSaturationAnalysis{
		VariantName:       variantName,
		ReplicaCount:      len(metrics),
		SaturatedReplicas: []string{},
	}

	if len(metrics) > 0 {
		analysis.AcceleratorName = metrics[0].AcceleratorName
		analysis.Cost = metrics[0].Cost
		logger.Log.Debugf("Variant analysis initialized: variant=%s, accelerator=%s, cost=%.2f, replicaCount=%d",
			variantName, analysis.AcceleratorName, analysis.Cost, len(metrics))
	}

	var totalSpareKv float64
	var totalSpareQueue float64
	var nonSaturatedCount int

	for _, metric := range metrics {
		// Check if replica is saturated
		isSaturated := metric.KvCacheUsage >= config.KvCacheThreshold ||
			float64(metric.QueueLength) >= config.QueueLengthThreshold

		if isSaturated {
			analysis.SaturatedReplicas = append(analysis.SaturatedReplicas, metric.PodName)
		} else {
			// Calculate spare Saturation for non-saturated replica
			spareKv := config.KvCacheThreshold - metric.KvCacheUsage
			spareQueue := config.QueueLengthThreshold - float64(metric.QueueLength)

			totalSpareKv += spareKv
			totalSpareQueue += spareQueue
			nonSaturatedCount++
		}

		// Track max usage
		if metric.KvCacheUsage > analysis.MaxKvCacheUsage {
			analysis.MaxKvCacheUsage = metric.KvCacheUsage
		}
		if metric.QueueLength > analysis.MaxQueueLength {
			analysis.MaxQueueLength = metric.QueueLength
		}
	}

	analysis.NonSaturatedCount = nonSaturatedCount

	// Calculate averages for non-saturated replicas
	if nonSaturatedCount > 0 {
		analysis.AvgSpareKvCapacity = totalSpareKv / float64(nonSaturatedCount)
		analysis.AvgSpareQueueLength = totalSpareQueue / float64(nonSaturatedCount)
	}

	return analysis
}

// shouldScaleUp determines if scale-up is needed based on spare Saturation triggers
func (a *Analyzer) shouldScaleUp(
	avgSpareKv float64,
	avgSpareQueue float64,
	config interfaces.SaturationScalingConfig,
) (bool, string) {

	kvTriggered := avgSpareKv < config.KvSpareTrigger
	queueTriggered := avgSpareQueue < config.QueueSpareTrigger

	// Early return if no triggers fired
	if !kvTriggered && !queueTriggered {
		return false, ""
	}

	// Build reason string based on which trigger(s) fired
	switch {
	case kvTriggered && queueTriggered:
		return true, fmt.Sprintf("both KV spare (%.3f < %.3f) and queue spare (%.1f < %.1f)",
			avgSpareKv, config.KvSpareTrigger, avgSpareQueue, config.QueueSpareTrigger)
	case kvTriggered:
		return true, fmt.Sprintf("KV spare Saturation low (%.3f < %.3f)",
			avgSpareKv, config.KvSpareTrigger)
	default: // only queueTriggered is true
		return true, fmt.Sprintf("queue spare Saturation low (%.1f < %.1f)",
			avgSpareQueue, config.QueueSpareTrigger)
	}
}

// isScaleDownSafe simulates realistic load redistribution after removing one replica.
// Returns (shouldScaleDown, isSafe) where:
// - shouldScaleDown: always false (saturation analyzer only approves, doesn't initiate scale-down)
// - isSafe: true if removing one replica would leave adequate headroom
//
// Algorithm: Calculates total current load across non-saturated replicas, then simulates
// redistributing that load across (N-1) replicas to determine if spare Saturation remains adequate.
func (a *Analyzer) isScaleDownSafe(
	replicaMetrics []interfaces.ReplicaMetrics,
	config interfaces.SaturationScalingConfig,
) (bool, bool) {

	// Collect non-saturated replicas
	var nonSaturatedMetrics []interfaces.ReplicaMetrics
	for _, m := range replicaMetrics {
		isSaturated := m.KvCacheUsage >= config.KvCacheThreshold ||
			float64(m.QueueLength) >= config.QueueLengthThreshold
		if !isSaturated {
			nonSaturatedMetrics = append(nonSaturatedMetrics, m)
		}
	}

	nonSaturatedCount := len(nonSaturatedMetrics)

	// Require minimum non-saturated replicas for scale-down safety
	// With fewer replicas, we cannot safely redistribute load without risking saturation
	if nonSaturatedCount < MinNonSaturatedReplicasForScaleDown {
		logger.Log.Debugf("Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=%d, required=%d",
			nonSaturatedCount, MinNonSaturatedReplicasForScaleDown)
		return false, false
	}

	// Calculate total load across all non-saturated replicas
	var totalKvLoad float64
	var totalQueueLoad int
	for _, m := range nonSaturatedMetrics {
		totalKvLoad += m.KvCacheUsage
		totalQueueLoad += m.QueueLength
	}

	// Simulate removing one replica: redistribute total load across remaining replicas
	remainingCount := nonSaturatedCount - 1
	avgKvAfterRemoval := totalKvLoad / float64(remainingCount)
	avgQueueAfterRemoval := float64(totalQueueLoad) / float64(remainingCount)

	// Calculate spare Saturation after redistribution
	remainingSpareKv := config.KvCacheThreshold - avgKvAfterRemoval
	remainingSpareQueue := config.QueueLengthThreshold - avgQueueAfterRemoval

	// Safe if both spare margins still exceed triggers
	kvSafe := remainingSpareKv >= config.KvSpareTrigger
	queueSafe := remainingSpareQueue >= config.QueueSpareTrigger

	isSafe := kvSafe && queueSafe

	if !isSafe {
		logger.Log.Debugf("Scale-down unsafe: insufficient headroom after redistribution: remainingSpareKv=%.3f, kvTrigger=%.3f, kvSafe=%v, remainingSpareQueue=%.1f, queueTrigger=%.1f",
			remainingSpareKv, config.KvSpareTrigger, kvSafe, remainingSpareQueue, config.QueueSpareTrigger, queueSafe)
	}

	// Saturation analyzer never initiates scale-down, only approves/denies
	return false, isSafe
}

// CalculateSaturationTargets determines target replicas per variant based on saturation analysis.
// Step 1: Pure saturation-based target calculation
// Uses replica count from Saturation metrics (ready replicas) to avoid excessive scale-up.
// Rules:
// - If desired ≠ 0 and desired ≠ current: target = desired (preserve previous optimizer decision)
// - Else if Saturation needs scale-up: cheapest variant gets readyReplicas+1
// - Else if Saturation allows scale-down: most expensive variant gets readyReplicas-1
// - Else: target = readyReplicas (replicas with metrics)
func (a *Analyzer) CalculateSaturationTargets(
	saturationAnalysis *interfaces.ModelSaturationAnalysis,
	variantStates []interfaces.VariantReplicaState,
) map[string]int {

	targets := make(map[string]int)

	// Nil safety
	if saturationAnalysis == nil || len(saturationAnalysis.VariantAnalyses) == 0 {
		// Default: current replicas
		for _, state := range variantStates {
			targets[state.VariantName] = state.CurrentReplicas
		}
		return targets
	}

	// Build state map for quick lookup
	stateMap := make(map[string]interfaces.VariantReplicaState)
	for _, state := range variantStates {
		stateMap[state.VariantName] = state
	}

	// Initialize all targets to ready replicas (those with metrics)
	// This prevents excessive scale-up when replicas are not yet ready
	for _, va := range saturationAnalysis.VariantAnalyses {
		targets[va.VariantName] = va.ReplicaCount
	}

	// Check if we should preserve any desired replicas
	// If desired ≠ 0 and desired ≠ current, preserve desired
	preservedVariants := make(map[string]bool)
	for _, va := range saturationAnalysis.VariantAnalyses {
		state := stateMap[va.VariantName]
		if state.DesiredReplicas != 0 && state.DesiredReplicas != state.CurrentReplicas {
			targets[va.VariantName] = state.DesiredReplicas
			preservedVariants[va.VariantName] = true
			logger.Log.Debugf("Preserving desired replicas: variant=%s, currentReplicas=%d, readyReplicas=%d, desired=%d",
				va.VariantName, state.CurrentReplicas, va.ReplicaCount, state.DesiredReplicas)
		}
	}

	// Determine Saturation action
	if saturationAnalysis.ShouldScaleUp {
		// Find cheapest variant that doesn't have preserved desired
		var cheapestNonPreserved *interfaces.VariantSaturationAnalysis
		for i := range saturationAnalysis.VariantAnalyses {
			va := &saturationAnalysis.VariantAnalyses[i]
			if preservedVariants[va.VariantName] {
				continue
			}
			// Select cheapest, with stable tie-breaking by variant name (alphabetically first)
			if cheapestNonPreserved == nil ||
				va.Cost < cheapestNonPreserved.Cost ||
				(va.Cost == cheapestNonPreserved.Cost && va.VariantName < cheapestNonPreserved.VariantName) {
				cheapestNonPreserved = va
			}
		}

		if cheapestNonPreserved != nil {
			state := stateMap[cheapestNonPreserved.VariantName]
			targets[cheapestNonPreserved.VariantName] = cheapestNonPreserved.ReplicaCount + 1
			logger.Log.Infof("Saturation target: scale-up cheapest variant: variant=%s, cost=%.2f, currentReplicas=%d, readyReplicas=%d, target=%d, reason=%s",
				cheapestNonPreserved.VariantName, cheapestNonPreserved.Cost, state.CurrentReplicas,
				cheapestNonPreserved.ReplicaCount, targets[cheapestNonPreserved.VariantName], saturationAnalysis.ScaleUpReason)
		}

	} else if saturationAnalysis.ScaleDownSafe {
		// Find most expensive variant that doesn't have preserved desired
		var mostExpensiveNonPreserved *interfaces.VariantSaturationAnalysis
		for i := range saturationAnalysis.VariantAnalyses {
			va := &saturationAnalysis.VariantAnalyses[i]
			if preservedVariants[va.VariantName] {
				continue
			}
			// Can't scale down if at or below minimum (1 replica)
			if va.ReplicaCount <= 1 {
				continue
			}
			// Select most expensive, with stable tie-breaking by variant name
			if mostExpensiveNonPreserved == nil ||
				va.Cost > mostExpensiveNonPreserved.Cost ||
				(va.Cost == mostExpensiveNonPreserved.Cost && va.VariantName > mostExpensiveNonPreserved.VariantName) {
				mostExpensiveNonPreserved = va
			}
		}

		if mostExpensiveNonPreserved != nil {
			state := stateMap[mostExpensiveNonPreserved.VariantName]
			targets[mostExpensiveNonPreserved.VariantName] = mostExpensiveNonPreserved.ReplicaCount - 1
			logger.Log.Infof("Saturation target: scale-down most expensive variant: variant=%s, cost=%.2f, currentReplicas=%d, readyReplicas=%d, target=%d",
				mostExpensiveNonPreserved.VariantName, mostExpensiveNonPreserved.Cost, state.CurrentReplicas,
				mostExpensiveNonPreserved.ReplicaCount, targets[mostExpensiveNonPreserved.VariantName])
		}
	} else {
		// No scaling action needed - Saturation is adequate and stable
		logger.Log.Debugf("Saturation targets: no scaling needed (avgSpareKv=%.3f, avgSpareQueue=%.1f, all variants stable)",
			saturationAnalysis.AvgSpareKvCapacity, saturationAnalysis.AvgSpareQueueLength)
	}

	return targets
}

// ArbitrateWithModelBased arbitrates between Saturation targets and model-based optimizer targets.
// Step 2: Arbitration using hybrid decision matrix
// Applies saturation safety overrides:
// - Saturation wants scale-up but model-based wants scale-down → veto (no change or scale-up)
// - Model-based wants scale-down but Saturation unsafe → safety block (no change)
// - Otherwise: follow model-based recommendation if Saturation allows
func (a *Analyzer) ArbitrateWithModelBased(
	saturationAnalysis *interfaces.ModelSaturationAnalysis,
	saturationTargets map[string]int,
	modelBasedTargets map[string]int,
	variantStates []interfaces.VariantReplicaState,
) []interfaces.VariantDecision {

	decisions := make([]interfaces.VariantDecision, 0, len(variantStates))

	// Build variant analysis map
	variantAnalysisMap := make(map[string]*interfaces.VariantSaturationAnalysis)
	if saturationAnalysis != nil {
		for i := range saturationAnalysis.VariantAnalyses {
			va := &saturationAnalysis.VariantAnalyses[i]
			variantAnalysisMap[va.VariantName] = va
		}
	}

	// Build state map
	stateMap := make(map[string]interfaces.VariantReplicaState)
	for _, state := range variantStates {
		stateMap[state.VariantName] = state
	}

	// Arbitrate for each variant
	for _, state := range variantStates {
		va := variantAnalysisMap[state.VariantName]
		saturationTarget := saturationTargets[state.VariantName]
		modelBasedTarget := modelBasedTargets[state.VariantName]

		decision := a.arbitrateVariant(
			saturationAnalysis,
			va,
			state,
			saturationTarget,
			modelBasedTarget,
		)

		decisions = append(decisions, decision)
	}

	return decisions
}

// arbitrateVariant applies hybrid decision matrix for a single variant
func (a *Analyzer) arbitrateVariant(
	modelAnalysis *interfaces.ModelSaturationAnalysis,
	variantAnalysis *interfaces.VariantSaturationAnalysis,
	state interfaces.VariantReplicaState,
	SaturationTarget int,
	modelBasedTarget int,
) interfaces.VariantDecision {

	decision := interfaces.VariantDecision{
		VariantName:     state.VariantName,
		CurrentReplicas: state.CurrentReplicas,
		DesiredReplicas: state.DesiredReplicas,
	}

	// Populate fields from modelAnalysis (nil-safe)
	if modelAnalysis != nil {
		decision.Namespace = modelAnalysis.Namespace
		decision.ModelID = modelAnalysis.ModelID
	}

	// Populate fields from variantAnalysis (nil-safe)
	if variantAnalysis != nil {
		decision.AcceleratorName = variantAnalysis.AcceleratorName
		decision.Cost = variantAnalysis.Cost
	}

	// Determine actions
	var saturationAction interfaces.SaturationAction
	if SaturationTarget > state.CurrentReplicas {
		saturationAction = interfaces.ActionScaleUp
	} else if SaturationTarget < state.CurrentReplicas {
		saturationAction = interfaces.ActionScaleDown
	} else {
		saturationAction = interfaces.ActionNoChange
	}

	var modelBasedAction interfaces.SaturationAction
	if modelBasedTarget > state.CurrentReplicas {
		modelBasedAction = interfaces.ActionScaleUp
	} else if modelBasedTarget < state.CurrentReplicas {
		modelBasedAction = interfaces.ActionScaleDown
	} else {
		modelBasedAction = interfaces.ActionNoChange
	}

	// Apply hybrid decision matrix
	switch {
	case saturationAction == interfaces.ActionScaleUp && modelBasedAction == interfaces.ActionScaleDown:
		// Saturation veto: model-based wants to scale down but Saturation needs more
		decision.Action = interfaces.ActionNoChange
		decision.TargetReplicas = state.CurrentReplicas
		decision.Reason = fmt.Sprintf("Saturation veto: Saturation needs scale-up (Saturation=%d, model-based=%d)",
			SaturationTarget, modelBasedTarget)
		decision.SafetyOverride = true
		decision.SaturationBased = true
		decision.ModelBasedDecision = true

	case modelBasedAction == interfaces.ActionScaleDown && modelAnalysis != nil && !modelAnalysis.ScaleDownSafe:
		// Safety block: model-based wants scale-down but Saturation says unsafe
		decision.Action = interfaces.ActionNoChange
		decision.TargetReplicas = state.CurrentReplicas
		decision.Reason = fmt.Sprintf("saturation safety block: scale-down unsafe (model-based wants %d)",
			modelBasedTarget)
		decision.SafetyOverride = true
		decision.SaturationBased = true
		decision.ModelBasedDecision = true

	case saturationAction == interfaces.ActionScaleUp && modelBasedAction == interfaces.ActionNoChange:
		// Saturation-driven scale-up (model-based doesn't object)
		decision.Action = interfaces.ActionScaleUp
		decision.TargetReplicas = SaturationTarget
		decision.Reason = fmt.Sprintf("Saturation-driven scale-up to %d", SaturationTarget)
		decision.SaturationBased = true
		decision.ModelBasedDecision = false

	case modelBasedAction == interfaces.ActionScaleUp || modelBasedAction == interfaces.ActionScaleDown:
		// Follow model-based recommendation (Saturation allows it)
		decision.Action = modelBasedAction
		decision.TargetReplicas = modelBasedTarget
		decision.Reason = fmt.Sprintf("model-based recommendation: %s to %d (Saturation allows)",
			modelBasedAction, modelBasedTarget)
		decision.SaturationBased = false
		decision.ModelBasedDecision = true

	default:
		// No change
		decision.Action = interfaces.ActionNoChange
		decision.TargetReplicas = state.CurrentReplicas
		decision.Reason = "no action needed"
		decision.SaturationBased = false
		decision.ModelBasedDecision = false
	}

	logger.Log.Info("Variant decision arbitrated",
		"variant", state.VariantName,
		"current", state.CurrentReplicas,
		"SaturationTarget", SaturationTarget,
		"modelBasedTarget", modelBasedTarget,
		"action", decision.Action,
		"targetReplicas", decision.TargetReplicas,
		"reason", decision.Reason)

	return decision
}
