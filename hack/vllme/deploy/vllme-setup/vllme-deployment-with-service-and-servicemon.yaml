apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllme-deployment
  # labels:
  #   inferno.server.managed: "true"
  #   inferno.server.name: vllm-001
  #   inferno.server.model: llama_13b
  #   inferno.server.class: Premium
  #   inferno.server.allocation.accelerator: MI250
  #   inferno.server.allocation.maxbatchsize: "8"
  #   inferno.server.load.rpm: "30.2"
  #   inferno.server.load.numtokens: "1560"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllme
  template:
    metadata:
      labels:
        app: vllme
    spec:
      containers:
      - name: vllme
        image: quay.io/infernoautoscaler/vllme:slim-1.0
        imagePullPolicy: Always
        env:
          - name: DECODE_TIME
            value: "20"
          - name: PREFILL_TIME
            value: "20"
          - name: AVG_TOKENS
            value: "128"
          - name: TOKENS_DISTRIBUTION
            value: "deterministic"
          - name: MAX_BATCH_SIZE
            value: "8"
          - name: KVC_PER_TOKEN
            value: "2"
        ports:
        - containerPort: 80
        resources:
          limits:
            cpu: 500m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 500Mi
---
apiVersion: v1
kind: Service
metadata:
  name: vllme-service
  labels:
    app: vllme
spec:
  selector:
    app: vllme  
  ports:
    - name: vllme
      port: 80
      protocol: TCP
      targetPort: 80
      nodePort: 30000
  type: NodePort
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: vllme-servicemonitor
  labels:
    app: vllme
spec:
  selector:
    matchLabels:
      app: vllme
  endpoints:
  - port: vllme
    path: /metrics
    interval: 15s
  namespaceSelector:
    any: true
---
