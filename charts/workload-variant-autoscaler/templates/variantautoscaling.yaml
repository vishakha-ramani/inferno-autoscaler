{{- if .Values.va.enabled }}
apiVersion: llmd.ai/v1alpha1
# Optimizing a variant, create only when the model is deployed and serving traffic
# this is for the collector the collect existing (previous) running metrics of the variant.
kind: VariantAutoscaling
metadata:
  # Unique name of the variant
  name: {{ printf "%s-decode" .Values.llmd.modelName }}
  namespace: {{ .Values.llmd.namespace }}
  labels:
    inference.optimization/acceleratorName: {{ .Values.va.accelerator }}
# This is essentially static input to the optimizer
spec:
  # ScaleTargetRef references the target resource to scale (similar to HPA)
  # TODO: Support templating for scaleTargetRef to enable managing groups of deployments
  scaleTargetRef:
    kind: Deployment
    name: {{ .Values.llmd.deploymentName | default (printf "%s-decode" .Values.llmd.modelName) }}
  # OpenAI API compatible name of the model
  modelID: {{ .Values.llmd.modelID | quote }}
  {{- if .Values.wva.experimentalHybridOptimization }}
  
  # Flag used to enable tuning for the VariantAutoscaling
  activateModelTuner: {{ .Values.va.tuned }}

  # Static profiled benchmarked data for a variant running on different accelerators
  modelProfile:
    accelerators:
      - acc: "H100"
        accCount: 1
        perfParms: 
          decodeParms:
            # Decode parameters for ITL equation: itl = alpha + beta * maxBatchSize
            alpha: "7.470"
            beta: "0.044"
          # Prefill parameters for TTFT equation: ttft = gamma + delta * tokens * maxBatchSize  
          prefillParms:
            gamma: "15.415"
            delta: "0.000337"
        maxBatchSize: 512
      - acc: "A100"
        accCount: 1
        perfParms: 
          decodeParms:
            # Decode parameters for ITL equation: itl = alpha + beta * maxBatchSize
            alpha: "20.58"
            beta: "0.41"
          # Prefill parameters for TTFT equation: ttft = gamma + delta * tokens * maxBatchSize  
          prefillParms:
            gamma: "5.2"
            delta: "0.1"
        maxBatchSize: 4
  {{- end}}
{{- end }}
